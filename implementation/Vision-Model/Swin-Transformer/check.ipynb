{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### swin transformer paper (https://arxiv.org/pdf/2103.14030.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of model parameters: 87,768,224\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "model = timm.create_model(\"swin_base_patch4_window7_224\")\n",
    "print('the number of model parameters: {:,}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "print(model.absolute_pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3136, 128])\n",
      "torch.Size([2, 3136, 128])\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"swin_base_patch4_window7_224\")\n",
    "\n",
    "inputs = torch.randn((2,3,224,224))\n",
    "# print(model(inputs).shape)\n",
    "\n",
    "inputs = model.patch_embed(inputs)\n",
    "print(inputs.shape) # (B, 3136, 128)\n",
    "\n",
    "inputs = model.layers[0].blocks[0](inputs)\n",
    "print(inputs.shape) # (B, 3136, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "\n",
      "(56, 56)\n",
      "(28, 28)\n",
      "(14, 14)\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "# (56, 56)  <==  actual fed image size {patch size = 4  -->  inputs image H, W = 224  -->  224/4 = 56}\n",
    "print(model.patch_embed.grid_size)\n",
    "print()\n",
    "\n",
    "# The input image resolution is gradually decreasing!!!!\n",
    "for i in range(len(model.layers)):\n",
    "    print(model.layers[i].input_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample (56, 56)\n",
      "2\n",
      "----------\n",
      "downsample (28, 28)\n",
      "2\n",
      "----------\n",
      "downsample (14, 14)\n",
      "18\n",
      "----------\n",
      "2\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if i+1 < len(model.layers):\n",
    "        print(\"downsample\",layer.downsample.input_resolution)\n",
    "    print(len(layer.blocks))\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of model parameters: 86,567,656\n"
     ]
    }
   ],
   "source": [
    "vit = timm.create_model(\"vit_base_patch16_224\")\n",
    "print('the number of model parameters: {:,}'.format(sum([p.data.nelement() for p in vit.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.],\n",
      "         [ 6.,  7.,  8.,  9.],\n",
      "         [11., 12., 13., 14.],\n",
      "         [16., 17., 18., 19.]]])\n",
      "----------\n",
      "tensor([[[ 1.,  3.],\n",
      "         [11., 13.]]])\n",
      "----------\n",
      "tensor([[[ 6.,  8.],\n",
      "         [16., 18.]]])\n",
      "----------\n",
      "tensor([[[ 2.,  4.],\n",
      "         [12., 14.]]])\n",
      "----------\n",
      "tensor([[[ 7.,  9.],\n",
      "         [17., 19.]]])\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([\n",
    "    [[1,2,3,4],\n",
    "     [6,7,8,9],\n",
    "     [11,12,13,14],\n",
    "     [16,17,18,19]]\n",
    "])\n",
    "\n",
    "print(x)\n",
    "print(\"-\"*10)\n",
    "x1 = x[:, 0::2, 0::2]\n",
    "print(x1)\n",
    "print(\"-\"*10)\n",
    "x2 = x[:, 1::2, 0::2]\n",
    "print(x2)\n",
    "print(\"-\"*10)\n",
    "x3 = x[:, 0::2, 1::2]\n",
    "print(x3)\n",
    "print(\"-\"*10)\n",
    "x4 = x[:, 1::2, 1::2]\n",
    "print(x4)\n",
    "print(\"-\"*10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of model parameters: 87,768,224\n",
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import swin_transformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_kwargs = dict(\n",
    "        patch_size=4, \n",
    "        window_size=7,\n",
    "        embed_dim=128,\n",
    "        depths=(2, 2, 18, 2),\n",
    "        num_heads=(4, 8, 16, 32)\n",
    "    )\n",
    "model = swin_transformer.SwinTransformer(**model_kwargs)\n",
    "print('the number of model parameters: {:,}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "x = torch.randn((2,3,224,224))\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.004)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.013)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.017)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.022)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.026)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.030)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.035)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.039)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.043)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.048)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.052)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.057)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.061)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.065)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.070)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.074)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.078)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.083)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.096)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchEmbed(\n",
      "  (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "torch.Size([2, 3136, 128])\n"
     ]
    }
   ],
   "source": [
    "patch_embed = model.patch_embed\n",
    "x = patch_embed(x)\n",
    "print(patch_embed)\n",
    "print(x.shape) # 56x56 = 3136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "H, W: 56, 56\n",
      "torch.Size([64, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 28, 28\n",
      "torch.Size([16, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "H, W: 14, 14\n",
      "torch.Size([4, 49, 49])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 3136, 128])\n",
      "shift_size: 0\n",
      "attn_mask: <class 'NoneType'>\n",
      "1) torch.Size([2, 56, 56, 128])\n",
      "2-1) torch.Size([128, 7, 7, 128])\n",
      "2-2) torch.Size([128, 49, 128])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      ">>>>>> qkv: torch.Size([3, 128, 4, 49, 32])\n",
      ">>>>>> q: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> k: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> v: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      "3) torch.Size([128, 49, 128])\n",
      "4) torch.Size([128, 7, 7, 128])\n",
      "5) torch.Size([2, 56, 56, 128])\n",
      "6) torch.Size([2, 56, 56, 128])\n",
      "7) torch.Size([2, 3136, 128])\n",
      "8) torch.Size([2, 3136, 128])\n",
      "torch.Size([2, 3136, 128])\n",
      "-----------\n",
      "shift_size: 3\n",
      "attn_mask: <class 'torch.Tensor'>\n",
      "attn_mask: torch.Size([64, 49, 49])\n",
      "1) torch.Size([2, 56, 56, 128])\n",
      "2-1) torch.Size([128, 7, 7, 128])\n",
      "2-2) torch.Size([128, 49, 128])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      ">>>>>> qkv: torch.Size([3, 128, 4, 49, 32])\n",
      ">>>>>> q: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> k: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> v: torch.Size([128, 4, 49, 32])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> attn: torch.Size([2, 64, 4, 49, 49])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> attn: torch.Size([128, 4, 49, 49])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      ">>>>>> x: torch.Size([128, 49, 128])\n",
      "3) torch.Size([128, 49, 128])\n",
      "4) torch.Size([128, 7, 7, 128])\n",
      "5) torch.Size([2, 56, 56, 128])\n",
      "6) torch.Size([2, 56, 56, 128])\n",
      "7) torch.Size([2, 3136, 128])\n",
      "8) torch.Size([2, 3136, 128])\n",
      "torch.Size([2, 3136, 128])\n",
      "-----------\n",
      "torch.Size([2, 784, 256])\n",
      "###############################\n",
      "shift_size: 0\n",
      "attn_mask: <class 'NoneType'>\n",
      "1) torch.Size([2, 28, 28, 256])\n",
      "2-1) torch.Size([32, 7, 7, 256])\n",
      "2-2) torch.Size([32, 49, 256])\n",
      ">>>>>> x: torch.Size([32, 49, 256])\n",
      ">>>>>> qkv: torch.Size([3, 32, 8, 49, 32])\n",
      ">>>>>> q: torch.Size([32, 8, 49, 32])\n",
      ">>>>>> k: torch.Size([32, 8, 49, 32])\n",
      ">>>>>> v: torch.Size([32, 8, 49, 32])\n",
      ">>>>>> attn: torch.Size([32, 8, 49, 49])\n",
      ">>>>>> attn: torch.Size([32, 8, 49, 49])\n",
      ">>>>>> x: torch.Size([32, 49, 256])\n",
      ">>>>>> x: torch.Size([32, 49, 256])\n",
      "3) torch.Size([32, 49, 256])\n",
      "4) torch.Size([32, 7, 7, 256])\n",
      "5) torch.Size([2, 28, 28, 256])\n",
      "6) torch.Size([2, 28, 28, 256])\n",
      "7) torch.Size([2, 784, 256])\n",
      "8) torch.Size([2, 784, 256])\n",
      "torch.Size([2, 784, 256])\n"
     ]
    }
   ],
   "source": [
    "# x = model.layers[0](x)\n",
    "# print(x.shape)\n",
    "# x = model.layers[0].blocks\n",
    "import torch\n",
    "import swin_transformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_kwargs = dict(\n",
    "        patch_size=4, \n",
    "        window_size=7,\n",
    "        embed_dim=128,\n",
    "        depths=(2, 2, 18, 2),\n",
    "        num_heads=(4, 8, 16, 32)\n",
    "    )\n",
    "model = swin_transformer.SwinTransformer(**model_kwargs)\n",
    "x = torch.randn((2,3,224,224))\n",
    "x = model.patch_embed(x)\n",
    "print(x.shape)\n",
    "print(\"shift_size:\",model.layers[0].blocks[0].shift_size) # SwinTransformerBlock 1\n",
    "print(\"attn_mask:\",type(model.layers[0].blocks[0].attn_mask)) # SwinTransformerBlock 1\n",
    "print(model.layers[0].blocks[0](x).shape) # SwinTransformerBlock 1\n",
    "print(\"-----------\")\n",
    "print(\"shift_size:\",model.layers[0].blocks[1].shift_size) # SwinTransformerBlock 2\n",
    "print(\"attn_mask:\",type(model.layers[0].blocks[1].attn_mask)) # SwinTransformerBlock 2\n",
    "print(\"attn_mask:\",model.layers[0].blocks[1].attn_mask.shape) # SwinTransformerBlock 2\n",
    "print(model.layers[0].blocks[1](x).shape) # SwinTransformerBlock 2\n",
    "print(\"-----------\")\n",
    "x = model.layers[0].downsample(x)\n",
    "print(x.shape)\n",
    "print(\"###############################\")\n",
    "print(\"shift_size:\",model.layers[1].blocks[0].shift_size) # SwinTransformerBlock 2\n",
    "print(\"attn_mask:\",type(model.layers[1].blocks[0].attn_mask)) # SwinTransformerBlock 2\n",
    "print(model.layers[1].blocks[0](x).shape) # SwinTransformerBlock 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.]])\n",
      "tensor([[   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        [   0.,    0.,    0.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.],\n",
      "        [-100., -100., -100.,  ...,    0.,    0.,    0.]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(model.layers[0].blocks[1].attn_mask.shape[0]):\n",
    "    if model.layers[0].blocks[1].attn_mask[i].sum() < 0.:\n",
    "       break\n",
    "print(i)\n",
    "print(model.layers[0].blocks[1].attn_mask[6])\n",
    "print(model.layers[0].blocks[1].attn_mask[7])\n",
    "print(model.layers[0].blocks[1].attn_mask[8])\n",
    "print(model.layers[0].blocks[1].attn_mask[9])\n",
    "print(model.layers[0].blocks[1].attn_mask[62])\n",
    "print(model.layers[0].blocks[1].attn_mask[63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].blocks[0].shift_size)\n",
    "print(model.layers[0].blocks[1].shift_size)\n",
    "print()\n",
    "print(model.layers[2].blocks[0].shift_size)\n",
    "print(model.layers[2].blocks[1].shift_size)\n",
    "print(model.layers[2].blocks[2].shift_size)\n",
    "print(model.layers[2].blocks[3].shift_size)\n",
    "print(model.layers[2].blocks[4].shift_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn((3,32,32))\n",
    "q,k,v = x.unbind(0)\n",
    "print(q.shape)\n",
    "print(k.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(0, 1, None), slice(3, 2, None), slice(1, 5, None))\n"
     ]
    }
   ],
   "source": [
    "x = (slice(0,1), slice(3,2), slice(1,5,None))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(0, 1, None)\n",
      "slice(3, 2, None)\n",
      "slice(1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "for h in (slice(0,1), slice(3,2), slice(1,5,2)):\n",
    "\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 14, 1])\n",
      "torch.Size([4, 7, 7, 1])\n",
      "torch.Size([4, 49])\n",
      "torch.Size([4, 1, 49])\n",
      "torch.Size([4, 49, 1])\n",
      "torch.Size([4, 49, 49])\n"
     ]
    }
   ],
   "source": [
    "from swin_transformer import window_partition\n",
    "window_size = 7\n",
    "shift_size = 3\n",
    "x = torch.zeros((1,14,14))\n",
    "cnt = 0\n",
    "for h in (\n",
    "        slice(0, -window_size),\n",
    "        slice(-window_size, -shift_size),\n",
    "        slice(-shift_size, None)):\n",
    "    for w in (\n",
    "            slice(0, -window_size),\n",
    "            slice(-window_size, -shift_size),\n",
    "            slice(-shift_size, None)):\n",
    "        # print(h, w)\n",
    "        x[:,h,w] = cnt\n",
    "        cnt += 1\n",
    "        # print(x)\n",
    "        # print(\"----\")\n",
    "\n",
    "x = x.unsqueeze(-1)\n",
    "print(x.shape)\n",
    "mask_windows1 = window_partition(x, window_size)\n",
    "print(mask_windows1.shape)\n",
    "# for win in mask_windows:\n",
    "#     print(win.squeeze(-1))\n",
    "mask_windows = mask_windows1.view(-1, window_size * window_size)\n",
    "# for win in mask_windows:\n",
    "#     print(win.squeeze(-1))\n",
    "print(mask_windows.shape)\n",
    "print(mask_windows.unsqueeze(1).shape)\n",
    "print(mask_windows.unsqueeze(2).shape)\n",
    "attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "print(attn_mask.shape)\n",
    "# print(attn_mask[0])\n",
    "# print(attn_mask[1])\n",
    "# print(attn_mask[2])\n",
    "# for win in mask_windows:\n",
    "#     print(win.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 5., 5., 5.],\n",
      "         [3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 5., 5., 5.],\n",
      "         [3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 5., 5., 5.],\n",
      "         [3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 5., 5., 5.],\n",
      "         [6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 8., 8., 8.],\n",
      "         [6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 8., 8., 8.],\n",
      "         [6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 8., 8., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 2., 2., 2.]])\n",
      "tensor([[3., 3., 3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3., 3., 3.],\n",
      "        [6., 6., 6., 6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6., 6., 6., 6.]])\n",
      "tensor([[4., 4., 4., 4., 5., 5., 5.],\n",
      "        [4., 4., 4., 4., 5., 5., 5.],\n",
      "        [4., 4., 4., 4., 5., 5., 5.],\n",
      "        [4., 4., 4., 4., 5., 5., 5.],\n",
      "        [7., 7., 7., 7., 8., 8., 8.],\n",
      "        [7., 7., 7., 7., 8., 8., 8.],\n",
      "        [7., 7., 7., 7., 8., 8., 8.]])\n"
     ]
    }
   ],
   "source": [
    "for win in mask_windows1:\n",
    "    print(win.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])\n",
      "tensor([1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1.,\n",
      "        2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1.,\n",
      "        1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2.])\n",
      "tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
      "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.])\n",
      "tensor([4., 4., 4., 4., 5., 5., 5., 4., 4., 4., 4., 5., 5., 5., 4., 4., 4., 4.,\n",
      "        5., 5., 5., 4., 4., 4., 4., 5., 5., 5., 7., 7., 7., 7., 8., 8., 8., 7.,\n",
      "        7., 7., 7., 8., 8., 8., 7., 7., 7., 7., 8., 8., 8.])\n"
     ]
    }
   ],
   "source": [
    "for win in mask_windows:\n",
    "    print(win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "----------\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "----------\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0-3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "----------\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      " 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0-3.0-3.0-3.0-3.0-2.0-2.0-2.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-4.0-4.0-4.0-4.0-3.0-3.0-3.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0-1.0-1.0-1.0-1.0 0.0 0.0 0.0\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for win in attn_mask:\n",
    "    for h in range(len(win)):\n",
    "        for w in range(len(win[0])):\n",
    "            print(f\"{win[h,w].item():4}\", end='')\n",
    "        print()\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "----------\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "----------\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "----------\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0    0.0    0.0    0.0    0.0 -100.0 -100.0 -100.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      " -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0 -100.0 -100.0 -100.0 -100.0    0.0    0.0    0.0\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "for win in attn_mask:\n",
    "    for h in range(len(win)):\n",
    "        for w in range(len(win[0])):\n",
    "            print(f\"{win[h,w].item():7}\", end='')\n",
    "        print()\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.]],\n",
      "\n",
      "        [[2.],\n",
      "         [3.],\n",
      "         [4.]]])\n",
      "----------\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[[1., 2., 3.]],\n",
      "\n",
      "        [[1., 2., 3.]]])\n",
      "----------\n",
      "tensor([[[ 0., -1., -2.],\n",
      "         [ 1.,  0., -1.],\n",
      "         [ 2.,  1.,  0.]],\n",
      "\n",
      "        [[ 1.,  0., -1.],\n",
      "         [ 2.,  1.,  0.],\n",
      "         [ 3.,  2.,  1.]]])\n",
      "----------\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [-1.,  0.,  1.],\n",
      "         [-2., -1.,  0.]],\n",
      "\n",
      "        [[-1.,  0.,  1.],\n",
      "         [-2., -1.,  0.],\n",
      "         [-3., -2., -1.]]])\n",
      "----------\n",
      "tensor([[[   0., -100., -100.],\n",
      "         [-100.,    0., -100.],\n",
      "         [-100., -100.,    0.]],\n",
      "\n",
      "        [[-100.,    0., -100.],\n",
      "         [-100., -100.,    0.],\n",
      "         [-100., -100., -100.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([\n",
    "    [[1],[2],[3]],\n",
    "    [[2],[3],[4]]\n",
    "])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(\"----------\")\n",
    "y = torch.Tensor([\n",
    "    [[1,2,3]],\n",
    "    [[1,2,3]]\n",
    "])\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print(\"----------\")\n",
    "print(x-y)\n",
    "print(\"----------\")\n",
    "print(y-x)\n",
    "print(\"----------\")\n",
    "attn = y-x\n",
    "attn = attn.masked_fill(attn!=0, float(-100.0)).masked_fill(attn==0, float(0.0))\n",
    "print(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 16, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "y = torch.randn((1,3,32,32))\n",
    "torch.nn.PixelUnshuffle(2)(y).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65fe116ec29312474b580f4ecbad52a94f46ea3a142b15e85ff8e68848a207e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
